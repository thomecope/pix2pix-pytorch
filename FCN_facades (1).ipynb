{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FCN_facades.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4oK6yw6kHpi",
        "outputId": "5b911242-fa7e-4e38-df58-c5dc030e9492"
      },
      "source": [
        "import os \n",
        "drive_root = os.getcwd() + '/drive/MyDrive/eecs545project-main'\n",
        "%cd $drive_root"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/eecs545project-main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0Swlb_okZB2",
        "outputId": "ad77d966-1c01-4c94-d8f3-ad9bbf726281"
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from torch.utils.data import DataLoader\n",
        "from torchsummary import summary\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version:  1.10.0+cu111\n",
            "Torchvision Version:  0.11.1+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hYmqpeMpRU2"
      },
      "source": [
        "# First define some parameters\n",
        "model_name = \"resnet_fcn\"\n",
        "num_classes = 20\n",
        "batch_size = 8\n",
        "num_epochs = 50\n",
        "feature_extract = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJQKO0mUlgU2"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in zip(dataloaders[phase][0], dataloaders[phase][1]):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                outputs = model(inputs)[\"out\"]\n",
        "                # print(outputs.shape)\n",
        "                # print(labels.squeeze(0).shape)\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                      loss = criterion(outputs, labels)\n",
        "                      loss.backward()\n",
        "                      optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                preds = model(inputs)[\"out\"].argmax(1)\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase][0].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase][0].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VowdPpEgpFUl"
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_R5jTOYxcSv"
      },
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet_fcn\":\n",
        "        \"\"\" Resnet fcn model from pytorch\n",
        "        \"\"\"\n",
        "        model_ft = models.segmentation.fcn_resnet50(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        #first, change auxiliary\n",
        "        model_ft.aux_classifier = models.segmentation.fcn.FCNHead(1024, 13)\n",
        "        #next, the classifier\n",
        "        model_ft.classifier = models.segmentation.fcn.FCNHead(2048, 13)\n",
        "        input_size = 256\n",
        "    \n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "#print(model_ft)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3ZF1LvdB6H2"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_ft = model_ft.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdcJlSJaDOa0",
        "outputId": "d7f735d0-8346-4496-be6a-ab40eee837cc"
      },
      "source": [
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if True:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params to learn:\n",
            "\t classifier.0.weight\n",
            "\t classifier.1.weight\n",
            "\t classifier.1.bias\n",
            "\t classifier.4.weight\n",
            "\t classifier.4.bias\n",
            "\t aux_classifier.0.weight\n",
            "\t aux_classifier.1.weight\n",
            "\t aux_classifier.1.bias\n",
            "\t aux_classifier.4.weight\n",
            "\t aux_classifier.4.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKnT_HyW_vwI"
      },
      "source": [
        " test = Image.open(os.path.join(os.getcwd(),'segment/cmp_b0001.png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLzVX8n7ADOP",
        "outputId": "eebdf6ee-6558-4fab-a015-8f1e37f448c6"
      },
      "source": [
        "transform_list = [transforms.ToTensor()]\n",
        "transform = transforms.Compose(transform_list)\n",
        "torch.round(transform(test)*255).long().dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-goZKKjKoK5"
      },
      "source": [
        "# Next, define a dictionary of dataloaders for the training and validation\n",
        "from facades_dataset import FacadeDataset\n",
        "input_truth = FacadeDataset(os.getcwd() + '/input_images', False)\n",
        "segment = FacadeDataset(os.getcwd() + '/segment', True)\n",
        "train_dataset_truth, val_dataset_truth, test_dataset_truth = torch.utils.data.random_split(input_truth, [250, 64, 64], generator=torch.Generator().manual_seed(42))\n",
        "train_dataset_segment, val_dataset_segment, test_dataset_segment = torch.utils.data.random_split(segment, [250, 64, 64], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "\n",
        "train_loader_truth = DataLoader(train_dataset_truth, batch_size = 1)\n",
        "train_loader_segment = DataLoader(train_dataset_segment, batch_size=1)\n",
        "val_loader_truth = DataLoader(val_dataset_truth, batch_size = 1)\n",
        "val_loader_segment = DataLoader(val_dataset_segment, batch_size = 1)\n",
        "dataloaders_dict = {'train':[train_loader_truth, train_loader_segment], 'val':[val_loader_truth, val_loader_segment]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imQbrqKD-44N",
        "outputId": "34849564-ee17-4a37-e438-156141a1b472"
      },
      "source": [
        "torch.max(next(iter(train_dataset_segment)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(11)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIOdX45QIf06",
        "outputId": "3d29fabe-564e-494c-e4fd-3af59d97bdf1"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 1.8286 Acc: 26735.6400\n",
            "val Loss: 1.8348 Acc: 25434.8750\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 1.7280 Acc: 27868.3840\n",
            "val Loss: 1.7857 Acc: 24929.0000\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 1.6995 Acc: 28187.5720\n",
            "val Loss: 1.7631 Acc: 25056.9375\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 1.6766 Acc: 28493.7680\n",
            "val Loss: 1.7396 Acc: 25055.7500\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 1.6558 Acc: 28822.8520\n",
            "val Loss: 1.7162 Acc: 25196.7500\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 1.6354 Acc: 29226.0920\n",
            "val Loss: 1.6948 Acc: 25205.6406\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 1.6140 Acc: 29679.1640\n",
            "val Loss: 1.6699 Acc: 25168.9219\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 1.5922 Acc: 30200.3840\n",
            "val Loss: 1.6491 Acc: 24946.0781\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 1.5690 Acc: 30778.1080\n",
            "val Loss: 1.6187 Acc: 24724.6250\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 1.5446 Acc: 31427.3800\n",
            "val Loss: 1.6064 Acc: 24240.8125\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 1.5201 Acc: 32136.3200\n",
            "val Loss: 1.5828 Acc: 23777.9844\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 1.4939 Acc: 32864.0840\n",
            "val Loss: 1.5563 Acc: 23420.4219\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 1.4663 Acc: 33672.0680\n",
            "val Loss: 1.5365 Acc: 22919.8594\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 1.4385 Acc: 34506.8320\n",
            "val Loss: 1.5099 Acc: 22819.0469\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 1.4092 Acc: 35354.9960\n",
            "val Loss: 1.4791 Acc: 22468.4688\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 1.3794 Acc: 36206.8040\n",
            "val Loss: 1.4506 Acc: 22440.0156\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 1.3488 Acc: 37159.9560\n",
            "val Loss: 1.4211 Acc: 21961.5625\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 1.3173 Acc: 38058.8880\n",
            "val Loss: 1.3722 Acc: 21479.2344\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 1.2858 Acc: 38962.7840\n",
            "val Loss: 1.3367 Acc: 21296.3438\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 1.2555 Acc: 39841.2560\n",
            "val Loss: 1.3062 Acc: 21002.5625\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 1.2230 Acc: 40777.7160\n",
            "val Loss: 1.2687 Acc: 20801.0469\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 1.1906 Acc: 41641.8360\n",
            "val Loss: 1.2247 Acc: 20186.2969\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 1.1589 Acc: 42458.7760\n",
            "val Loss: 1.1999 Acc: 20268.0625\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 1.1263 Acc: 43342.0320\n",
            "val Loss: 1.1604 Acc: 20060.2500\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 1.0955 Acc: 44142.0880\n",
            "val Loss: 1.1168 Acc: 19869.4219\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 1.0654 Acc: 44958.5880\n",
            "val Loss: 1.0885 Acc: 19630.3125\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 1.0342 Acc: 45688.5080\n",
            "val Loss: 1.0536 Acc: 19448.6719\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 1.0084 Acc: 46350.5200\n",
            "val Loss: 1.0213 Acc: 19639.0469\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.9820 Acc: 46967.7280\n",
            "val Loss: 1.0050 Acc: 18784.1719\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.9538 Acc: 47596.9120\n",
            "val Loss: 0.9447 Acc: 19045.8281\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.9319 Acc: 48133.3640\n",
            "val Loss: 0.9210 Acc: 18261.6406\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.9111 Acc: 48595.3160\n",
            "val Loss: 0.8907 Acc: 18294.2031\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.8848 Acc: 49170.2880\n",
            "val Loss: 0.8639 Acc: 18079.0156\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.8746 Acc: 49409.1480\n",
            "val Loss: 0.8665 Acc: 16571.2188\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.8555 Acc: 49787.3480\n",
            "val Loss: 0.8633 Acc: 16424.2656\n",
            "\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.8527 Acc: 49800.9640\n",
            "val Loss: 0.8694 Acc: 16813.2031\n",
            "\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.8626 Acc: 49599.3520\n",
            "val Loss: 0.8782 Acc: 19108.5000\n",
            "\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 0.9168 Acc: 48352.5640\n",
            "val Loss: 0.8856 Acc: 22188.8438\n",
            "\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 0.8738 Acc: 49294.5360\n",
            "val Loss: 0.8246 Acc: 21341.2969\n",
            "\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 0.8580 Acc: 49716.8080\n",
            "val Loss: 0.8068 Acc: 20218.0469\n",
            "\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 0.8168 Acc: 50534.6840\n",
            "val Loss: 0.7770 Acc: 20218.3906\n",
            "\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 0.7943 Acc: 50957.6840\n",
            "val Loss: 0.7586 Acc: 19611.8594\n",
            "\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 0.7837 Acc: 51150.7040\n",
            "val Loss: 0.7497 Acc: 17888.9688\n",
            "\n",
            "Epoch 43/49\n",
            "----------\n",
            "train Loss: 0.7891 Acc: 50982.3480\n",
            "val Loss: 0.7615 Acc: 18107.5938\n",
            "\n",
            "Epoch 44/49\n",
            "----------\n",
            "train Loss: 0.7990 Acc: 50716.5280\n",
            "val Loss: 0.7259 Acc: 18587.4062\n",
            "\n",
            "Epoch 45/49\n",
            "----------\n",
            "train Loss: 0.7959 Acc: 50806.7680\n",
            "val Loss: 0.6791 Acc: 20332.0312\n",
            "\n",
            "Epoch 46/49\n",
            "----------\n",
            "train Loss: 0.7644 Acc: 51429.8960\n",
            "val Loss: 0.6657 Acc: 21327.4219\n",
            "\n",
            "Epoch 47/49\n",
            "----------\n",
            "train Loss: 0.7351 Acc: 52045.5040\n",
            "val Loss: 0.6460 Acc: 21961.0156\n",
            "\n",
            "Epoch 48/49\n",
            "----------\n",
            "train Loss: 0.7061 Acc: 52652.9280\n",
            "val Loss: 0.6188 Acc: 21869.3750\n",
            "\n",
            "Epoch 49/49\n",
            "----------\n",
            "train Loss: 0.6906 Acc: 52985.8920\n",
            "val Loss: 0.6006 Acc: 22191.3750\n",
            "\n",
            "Training complete in 68m 56s\n",
            "Best val Acc: 25434.875000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "68Z7OGmMF3G7",
        "outputId": "22eb22ac-6bae-4736-dd6e-ac64765ea3b6"
      },
      "source": [
        "torch.save(model_ft.state_dict(), os.path.join(os.getcwd(), 'fcn_save_50epoch'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a7b3b55a43d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fcn_save_50epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxdJTBYGK30m"
      },
      "source": [
        "model_ft.eval()\n",
        "model_ft.cuda()\n",
        "output_sample = model_ft(next(iter(train_dataset_truth)).unsqueeze(0).to(device))[\"out\"]\n",
        "plt.imshow(output_sample.squeeze(0).argmax(0).cpu())\n",
        "print(output_sample.squeeze(0).argmax(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDSzQ0CKLDql"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}